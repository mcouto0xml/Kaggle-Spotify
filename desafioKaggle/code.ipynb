{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importação das bibliotecas\n",
    "Nesta etapa, importamos as bibliotecas e pacotes necessários para o desenvolvimento do projeto. As principais bibliotecas usadas são:\n",
    "\n",
    "- pandas: Para manipulação e análise de dados, fornecendo estrutura de dados flexível e eficiente.\n",
    "- matplotlib.pyplot e seaborn: Para visualização gráfica, facilitando a interpretação das características do dataset e dos resultados dos modelos.\n",
    "- LabelEncoder: Do sklearn, para converter colunas categóricas em numéricas, facilitando a aplicação de algoritmos de machine learning.\n",
    "- RandomForestClassifier: Um dos principais modelos de classificação utilizado para predizer a popularidade das músicas.\n",
    "- accuracy_score, confusion_matrix, classification_report: Ferramentas para avaliar a performance do modelo.\n",
    "- train_test_split: Para dividir os dados em conjuntos de treino e teste, garantindo uma avaliação justa.\n",
    "- RandomizedSearchCV: Para a otimização de hiperparâmetros de maneira mais eficiente, testando diferentes combinações."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importa as bibliotecas necessárias\n",
    "\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "from sklearn.model_selection import train_test_split, RandomizedSearchCV\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Carregamento dos dados\n",
    "Nesta etapa, os datasets de treino e teste foram carregados utilizando a função pd.read_csv(). O dataset de treino (df_train) será utilizado para ajustar o modelo de machine learning, enquanto o dataset de teste (df_test) será usado para fazer previsões e avaliar o modelo final.\n",
    "\n",
    "Além disso, uma cópia do dataset de teste foi feita (df_test_original) para preservar a integridade dos dados originais, permitindo comparações futuras e uma possível análise posterior sem alterações no conjunto de teste original."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_csv('train.csv')\n",
    "df_test = pd.read_csv('test.csv')\n",
    "df_test_original = df_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exploração Inicial dos Dados\n",
    "\n",
    "Aqui, utilizamos o método df_train.info() para obter uma visão geral da estrutura do dataset de treino. Essa função fornece informações importantes, como:\n",
    "\n",
    "- O número total de entradas (linhas) e colunas.\n",
    "- O tipo de dado de cada coluna (por exemplo, inteiro, float, ou objeto).\n",
    "- O número de valores não nulos presentes em cada coluna.\n",
    "\n",
    "Essa análise inicial ajuda a identificar possíveis problemas, como dados ausentes, e permite uma compreensão básica das variáveis que estão presentes no dataset, orientando as etapas subsequentes de limpeza e transformação dos dados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Informa dados sobre a tabela df_train\n",
    "\n",
    "df_train.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exploração Inicial dos Dados 2.0\n",
    "A função df_train.describe() fornece uma visão geral estatística das colunas numéricas do dataset. Essa função retorna métricas como:\n",
    "\n",
    "- Contagem (count): número de valores não nulos em cada coluna.\n",
    "- Média (mean): valor médio de cada coluna.\n",
    "- Desvio padrão (std): medida de dispersão dos dados em relação à média.\n",
    "- Valores mínimos e máximos (min/max): extremos da distribuição dos dados.\n",
    "- Quartis (25%, 50%, 75%): valores que dividem os dados em quartis, úteis para detectar a dispersão e a distribuição dos dados.\n",
    "\n",
    "Essa análise estatística preliminar permite identificar possíveis outliers, entender a distribuição dos dados e ter uma visão mais detalhada de como cada variável se comporta no dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Descreve os dados da tabela df_train\n",
    "\n",
    "df_train.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Detecção de Valores Nulos\n",
    "Nessa etapa, foi verificada a presença de valores ausentes (nulos) no dataset de treinamento utilizando df_train.isna().sum(). Nenhuma das colunas apresentou valores nulos, o que é um ótimo indicativo para a continuidade do processo de modelagem, já que não será necessário lidar com técnicas de imputação ou remoção de valores ausentes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verifica valores nulos em todas as colunas\n",
    "nulos = df_train.isna().sum()\n",
    "\n",
    "# Repetição para conferir a contagem de nulos\n",
    "for column in nulos:\n",
    "    if column > 0:\n",
    "        print(column)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Separação de colunas categóricas e numéricas\n",
    "\n",
    "Nesta etapa, as colunas do dataset foram separadas em categóricas e numéricas para facilitar o processamento subsequente. Colunas do tipo bool e object foram identificadas como categóricas, tanto no conjunto de treino quanto no de teste. Essas colunas foram armazenadas em listas separadas para serem manipuladas de forma específica.\n",
    "\n",
    "- cat_columns: Armazena as colunas categóricas do dataset de treino.\n",
    "- cat_columns_test: Armazena as colunas categóricas do dataset de teste.\n",
    "\n",
    "O dataset foi dividido em dois: df_train_cat e df_test_cat (contendo as colunas categóricas) e df_train_num (contendo as colunas numéricas). Isso permitirá que cada tipo de dado seja tratado de forma adequada em etapas futuras, como codificação de variáveis categóricas e normalização das numéricas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inicia valores de listas\n",
    "cat_columns = []\n",
    "cat_columns_test = []\n",
    "\n",
    "# Repetição para associar a lista as colunas categoricas e numéricas do df_train\n",
    "for column in df_train:\n",
    "    if df_train[column].dtype == 'bool':\n",
    "        cat_columns.append(column)\n",
    "\n",
    "    if df_train[column].dtype == 'object':\n",
    "        cat_columns.append(column)\n",
    "\n",
    "# Repetição para associar a lista as colunas categoricas e numéricas do df_test\n",
    "for column in df_test:\n",
    "    if df_train[column].dtype == 'bool':\n",
    "        cat_columns_test.append(column)\n",
    "\n",
    "    if df_train[column].dtype == 'object':\n",
    "        cat_columns_test.append(column)\n",
    "     \n",
    "\n",
    "# Associa as variáveis (dataframes) os valores das colunas categóricas e numéricas\n",
    "df_train_cat = df_train[cat_columns]\n",
    "df_train_num = df_train.drop(columns=cat_columns)\n",
    "\n",
    "df_test_cat = df_test[cat_columns_test]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exploração de Outliers\n",
    "Nesta etapa, exploramos a presença de outliers nas features numéricas usando gráficos de boxplot. Cada coluna numérica do conjunto de dados foi visualizada por meio de um boxplot, o que permite identificar valores atípicos que estão fora do intervalo interquartil (IQR).\n",
    "\n",
    "Para isso, foi criada uma grade de subplots de 5x3, onde cada gráfico exibe a distribuição de uma variável numérica específica. Essa análise visual é importante para entender a dispersão e a presença de possíveis outliers em cada feature, o que pode impactar o desempenho do modelo preditivo.\n",
    "\n",
    "Após a análise, será possível decidir se será necessário aplicar técnicas de tratamento de outliers, como remoção ou transformação dos dados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Criando boxplots para cada uma das colunas\n",
    "fig, axes = plt.subplots(5, 3, figsize=(15, 15))\n",
    "axes = axes.flatten()\n",
    "\n",
    "# Iterando sobre as colunas do DataFrame e plotando os boxplots\n",
    "for i, col in enumerate(df_train_num.columns):\n",
    "    axes[i].boxplot(df_train_num[col])\n",
    "    axes[i].set_title(f'Boxplot de {col}')\n",
    "    axes[i].set_ylabel(col)\n",
    "\n",
    "# Ajustando o layout para não sobrepor os gráficos\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Identificação e substituição de Outliers\n",
    "\n",
    "Nesta etapa, implementamos uma função para identificar e substituir outliers em nosso conjunto de dados numéricos usando o método do intervalo interquartil (IQR). A função identificar_outliers_iqr calcula os quartis (Q1 e Q3) e determina o IQR, definindo limites inferior e superior para detectar valores atípicos.\n",
    "\n",
    "Em seguida, aplicamos essa função ao DataFrame df_train_num para gerar um DataFrame booleano, onde cada valor indica se o respectivo elemento é um outlier.\n",
    "\n",
    "A função substituir_outliers é responsável por substituir esses outliers pelo valor da mediana da coluna correspondente, ajudando a mitigar a influência negativa que os outliers podem ter no modelo preditivo. Esse processo é repetido até que não sejam encontrados mais outliers no DataFrame, garantindo que os dados estejam mais limpos e prontos para o treinamento do modelo. Essa abordagem é crucial para melhorar a robustez do modelo, evitando que ele seja influenciado por valores extremos que não representam bem a distribuição da maioria dos dados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Função para identificar os ouliers a partir do método IQR\n",
    "def identificar_outliers_iqr(column):\n",
    "    Q1 = column.quantile(0.25)\n",
    "    Q3 = column.quantile(0.75)\n",
    "    IQR = Q3 - Q1\n",
    "    limite_inferior = Q1 - 1.5 * IQR\n",
    "    limite_superior = Q3 + 1.5 * IQR\n",
    "    return (column < limite_inferior) | (column > limite_superior)\n",
    "\n",
    "# Aplica a função no dataframe numérico de treino\n",
    "outliers = df_train_num.apply(identificar_outliers_iqr)\n",
    "\n",
    "# Cria uma função para substituir os outliers\n",
    "def substituir_outliers(df):\n",
    "    outliers = df_train_num.apply(identificar_outliers_iqr)\n",
    "    # Itera até que sejam substituidos todos outliers pela mediana\n",
    "    while outliers.any().any() == True:\n",
    "        for column in df.columns:\n",
    "            no_outliers = df.loc[~outliers[column], column]\n",
    "            median = no_outliers.median()\n",
    "            df.loc[outliers[column], column] = median\n",
    "        outliers = df.apply(identificar_outliers_iqr)\n",
    "    \n",
    "    return df\n",
    "\n",
    "# Aplica a função de substituir no dataframe número de treino\n",
    "substituir_outliers(df_train_num)\n",
    "\n",
    "for coluna in df_train_num.columns:\n",
    "    df_train[coluna] = df_train_num[coluna]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Análise de Correlação\n",
    "\n",
    "Nesta etapa, calculamos a matriz de correlação das variáveis numéricas no conjunto de treinamento utilizando o método corr() do pandas. A correlação é uma medida que indica a relação entre duas variáveis, variando de -1 a 1. Valores próximos a 1 indicam uma forte correlação positiva, enquanto valores próximos a -1 indicam uma forte correlação negativa. Valores próximos a 0 sugerem pouca ou nenhuma correlação.\n",
    "\n",
    "Para visualizar essa matriz de correlação de forma clara e informativa, utilizamos um gráfico de calor (heatmap) da biblioteca Seaborn. O gráfico foi configurado para exibir os coeficientes de correlação dentro de cada célula, facilitando a interpretação dos dados. A paleta de cores 'coolwarm' foi utilizada para destacar visualmente as correlações positivas e negativas.\n",
    "\n",
    "Essa análise é fundamental para entender como as variáveis se relacionam entre si e identificar quais features podem ser mais relevantes para o modelo preditivo, permitindo uma seleção de características mais informada e aumentando as chances de sucesso do modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calcular a matriz de correlação\n",
    "correlacao = df_train_num.corr()\n",
    "\n",
    "# Configura o tamanho da figura\n",
    "plt.figure(figsize=(10, 8))\n",
    "\n",
    "# Plotar a matriz de correlação\n",
    "sns.heatmap(correlacao, annot=True, cmap='coolwarm', linewidths=0.5)\n",
    "\n",
    "# Exibir o gráfico\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Codificação Inicial de Variáveis\n",
    "\n",
    "Nesta etapa, substituímos as colunas numéricas do DataFrame original de treinamento (df_train) pelas colunas processadas que não contêm outliers, que foram armazenadas em df_train_num. Isso garante que estamos utilizando um conjunto de dados mais limpo para o desenvolvimento do modelo preditivo.\n",
    "\n",
    "Além disso, realizamos a codificação da coluna explicit, que indica se uma música contém conteúdo explícito. Os valores 'FALSE' e 'TRUE' dessa coluna foram convertidos em valores numéricos, onde 'FALSE' foi substituído por 0 e 'TRUE' por 1. Esse tipo de transformação é essencial para que o modelo de aprendizado de máquina possa interpretar corretamente a variável categórica, já que a maioria dos algoritmos de machine learning, incluindo o Random Forest, trabalha melhor com dados numéricos.\n",
    "\n",
    "O mesmo procedimento foi aplicado ao conjunto de teste (df_test) para garantir que ambas as bases de dados tenham o mesmo formato e estrutura, permitindo que o modelo treinado seja aplicado de forma consistente nas previsões. Essa etapa é crucial para a integridade dos dados e para a eficácia do modelo preditivo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Associa os outliers tratados na coluna original\n",
    "for column in df_train_num:\n",
    "    df_train[column] = df_train_num[column]\n",
    "\n",
    "# Substitui os valores false e true para 0 e 1 respectivamente\n",
    "df_train.loc[df_train['explicit'] == 'FALSE'] = 0\n",
    "df_train.loc[df_train['explicit'] == 'TRUE'] = 1\n",
    "\n",
    "df_test.loc[df_test['explicit'] == 'FALSE'] = 0\n",
    "df_test.loc[df_test['explicit'] == 'TRUE'] = 1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preparações para a exploração e hipóteses\n",
    "Nesta etapa, realizamos a filtragem do DataFrame de treinamento (df_train) para criar subconjuntos específicos de músicas baseados em seu gênero. Os gêneros selecionados foram gospel, MPB (Música Popular Brasileira) e J-Pop (música pop japonesa). Para cada gênero, utilizamos a função loc para extrair apenas as linhas correspondentes a cada categoria.\n",
    "\n",
    "Após a filtragem, contamos a frequência dos valores da coluna popularity_target, que representa a popularidade das músicas dentro de cada gênero, utilizando a função value_counts(). Essa contagem nos fornece informações sobre quantas músicas possuem cada nível de popularidade (por exemplo, 0 ou 1).\n",
    "\n",
    "Esta análise é parte do processo de preparação dos dados para a exploração das variáveis, permitindo-nos entender como a popularidade das músicas varia entre diferentes gêneros."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Associa a uma variável, um dataframe onde armazena apenas as linhas onde a coluna 'track_genre' é igual ao genêro escolhido\n",
    "gospel = df_train.loc[df_train['track_genre'] == 'gospel']\n",
    "mpb = df_train.loc[df_train['track_genre'] == 'mpb']\n",
    "j_pop = df_train.loc[df_train['track_genre'] == 'j-pop']\n",
    "\n",
    "# Conta o número de valores achados por cada gênero\n",
    "gospel_pop = gospel['popularity_target'].value_counts()\n",
    "mpb_pop = mpb['popularity_target'].value_counts()\n",
    "j_pop_pop = j_pop['popularity_target'].value_counts()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hipótese 1\n",
    "Nesta etapa, formulamos uma hipótese que investiga a relação entre o gênero musical gospel e sua popularidade. Para isso, criamos um gráfico de pizza que ilustra a proporção de músicas gospel categorizadas como populares (1) e não populares (0).\n",
    "\n",
    "A visualização, gerada a partir dos dados filtrados na variável gospel_pop, nos permite observar a distribuição de popularidade dentro desse gênero. Com isso, buscamos responder à pergunta: \"As músicas gospel tendem a ser mais populares do que as não gospel?\"\n",
    "\n",
    "O gráfico de pizza apresenta as proporções de cada classe, facilitando a análise visual e a interpretação dos resultados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Formula os gráficos para o gênero gospel e sua relação com a proporção de popularidade\n",
    "labels = ['Popularidade 0', 'Popularidade 1']\n",
    "colors = ['#ff9999','#66b3ff'][:len(gospel_pop)]\n",
    "\n",
    "\n",
    "plt.figure(figsize=(6,6))\n",
    "plt.pie(gospel_pop, labels=labels, colors=colors, autopct='%1.1f%%', startangle=90)\n",
    "plt.title('Proporção de Popularidade (0 ou 1) para Gospel')\n",
    "plt.axis('equal')  # Equal aspect ratio para que o gráfico seja circular\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hipótese 2\n",
    "Nesta etapa, continuamos a formulação de hipóteses ao investigar a relação entre o gênero musical MPB (Música Popular Brasileira) e sua popularidade. Criamos um gráfico de pizza que ilustra a proporção de músicas MPB classificadas como populares (1) e não populares (0).\n",
    "\n",
    "O gráfico, gerado a partir dos dados filtrados na variável mpb_pop, nos ajuda a observar como as músicas desse gênero estão distribuídas em termos de popularidade. Isso nos leva a questionar: \"As músicas MPB têm uma taxa de popularidade similar ou diferente das músicas de outros gêneros?\"\n",
    "\n",
    "Ao visualizar essas proporções, buscamos identificar padrões que possam indicar se a MPB possui características únicas que influenciam sua popularidade. A interpretação clara desse gráfico é essencial para validar ou refutar nossa hipótese sobre a popularidade da música MPB."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Formula os gráficos para o gênero MPB e sua relação com a proporção de popularidade\n",
    "labels = ['Popularidade 0', 'Popularidade 1']\n",
    "colors = ['#ff9999','#66b3ff']\n",
    "\n",
    "\n",
    "plt.figure(figsize=(6,6))\n",
    "plt.pie(mpb_pop, labels=labels, colors=colors, autopct='%1.1f%%', startangle=90)\n",
    "plt.title('Proporção de Popularidade (0 ou 1) para MPB')\n",
    "plt.axis('equal')  # Equal aspect ratio para que o gráfico seja circular\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hipótese 3\n",
    "Nesta etapa, continuamos a formulação de hipóteses ao analisar a relação entre o gênero musical J-Pop (Japanese Pop) e sua popularidade. Utilizando um gráfico de pizza, apresentamos a proporção de músicas J-Pop categorizadas como populares (1) e não populares (0).\n",
    "\n",
    "O gráfico, gerado a partir dos dados filtrados na variável j_pop_pop, permite visualizar como as músicas desse gênero se distribuem em relação à popularidade. Isso nos leva a questionar: \"As músicas J-Pop apresentam uma taxa de popularidade distinta em comparação com outros gêneros musicais?\"\n",
    "\n",
    "Ao observar essas proporções, buscamos identificar tendências que possam sugerir se o J-Pop possui atributos específicos que influenciam sua aceitação e sucesso entre os ouvintes. A interpretação deste gráfico é fundamental para validar ou refutar nossa hipótese sobre a popularidade da música J-Pop."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Formula os gráficos para o gênero J-Pop e sua relação com a proporção de popularidade\n",
    "labels = ['Popularidade 0', 'Popularidade 1']\n",
    "colors = ['#ff9999','#66b3ff']\n",
    "\n",
    "\n",
    "plt.figure(figsize=(6,6))\n",
    "plt.pie(j_pop_pop, labels=labels, colors=colors, autopct='%1.1f%%', startangle=90)\n",
    "plt.title('Proporção de Popularidade (0 ou 1) para J-Pop')\n",
    "plt.axis('equal')  # Equal aspect ratio para que o gráfico seja circular\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Codificação de variáveis categóricas\n",
    "Nesta etapa, aplicamos a codificação das variáveis categóricas, especificamente a coluna track_genre, que representa os gêneros musicais das faixas. Como os modelos de machine learning, como o Random Forest, requerem entradas numéricas, utilizamos o LabelEncoder do scikit-learn para transformar os gêneros musicais em valores numéricos.\n",
    "\n",
    "O método fit_transform é aplicado ao conjunto de treinamento (df_train), onde cada gênero é mapeado para um número inteiro. Por exemplo, o gênero \"gospel\" pode ser codificado como 0, \"mpb\" como 1 e \"j-pop\" como 2, e assim por diante. Essa transformação é essencial para permitir que o modelo reconheça e utilize essas informações categóricas durante o treinamento.\n",
    "\n",
    "Em seguida, realizamos a mesma transformação no conjunto de teste (df_test) para garantir que ambos os conjuntos de dados estejam em um formato consistente. A codificação das variáveis categóricas é uma etapa crítica na preparação dos dados, pois garante que as informações relevantes dos gêneros musicais sejam corretamente interpretadas pelo modelo, contribuindo para a precisão das previsões de popularidade musical.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Codificando as features categóricas\n",
    "\n",
    "le = LabelEncoder()\n",
    "df_train['track_genre'] = le.fit_transform(df_train['track_genre'])\n",
    "df_test['track_genre'] = le.fit_transform(df_test['track_genre'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Seleção de feature\n",
    "\n",
    "Nesta etapa, realizamos a seleção de features, que é um processo essencial na construção de modelos preditivos. A seleção de features nos permite focar nas variáveis que mais impactam a previsão de nossa variável-alvo, neste caso, a popularidade da música.\n",
    "\n",
    "Decidimos remover do conjunto de dados as colunas categóricas que não contribuiriam significativamente para a previsão do modelo, especificamente: track_id, artists, album_name, track_name e explicit. Embora essas variáveis possam conter informações valiosas, elas não são diretamente úteis para prever a popularidade das músicas, especialmente porque explicit já foi codificado como uma variável numérica.\n",
    "\n",
    "O resultado dessa seleção é um conjunto de dados mais enxuto e focado, que contém apenas as features que se espera que tenham um impacto relevante na predição da popularidade. Essa abordagem não só ajuda a reduzir a complexidade do modelo, mas também pode melhorar o desempenho e a interpretabilidade do modelo ao evitar ruídos desnecessários nas variáveis. O mesmo processo de seleção de features foi aplicado ao conjunto de teste (df_test), assegurando consistência entre os dados utilizados para treinar e avaliar o modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Seleciona e exclui colunas para o treino do modelo\n",
    "df_train = df_train.drop(columns=['track_id', 'artists', 'album_name', 'track_name', 'explicit'])\n",
    "\n",
    "df_test = df_test.drop(columns=['track_id', 'artists', 'album_name', 'track_name', 'explicit'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Treinamento do modelo e avaliação do desempenho\n",
    "\n",
    "Nesta etapa, realizamos o treinamento do modelo de machine learning utilizando o RandomForestClassifier. A Random Forest é uma técnica robusta que utiliza múltiplas árvores de decisão para fazer previsões, o que a torna eficaz em tarefas de classificação como a nossa, onde buscamos prever a popularidade de músicas.\n",
    "\n",
    "Primeiramente, separamos os dados em variáveis independentes (X) e a variável dependente (y), que neste caso é a coluna popularity_target. Em seguida, dividimos o conjunto de dados em conjuntos de treinamento e teste utilizando a função train_test_split, reservando 30% dos dados para avaliação do modelo.\n",
    "\n",
    "Após a separação dos dados, treinamos o modelo com o conjunto de treinamento (X_train e y_train) e, em seguida, realizamos previsões no conjunto de teste (X_test). A acurácia obtida foi de 82,11%, indicando que o modelo conseguiu prever corretamente a popularidade das músicas em mais de 82% dos casos testados.\n",
    "\n",
    "Para uma avaliação mais detalhada, geramos uma matriz de confusão e um relatório de classificação, que fornecem insights sobre o desempenho do modelo em cada classe da variável-alvo. O relatório inclui métricas como precisão, recall e F1-score, que são fundamentais para entender a eficácia do modelo, especialmente em cenários de classificação desequilibrada.\n",
    "\n",
    "A matriz de confusão visualiza os acertos e erros do modelo, permitindo identificar onde ele está se saindo bem e onde pode melhorar. Essas informações são cruciais para futuras iterações no modelo e para ajustes que possam aumentar sua performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Supondo que 'target' é a coluna que você deseja prever\n",
    "X = df_train.drop(columns='popularity_target', axis=1) \n",
    "y = df_train['popularity_target']\n",
    "\n",
    "# Features do conjunto de teste\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# Criar e treinar o modelo RandomForestClassifier\n",
    "rf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "rf.fit(X_train, y_train)\n",
    "\n",
    "# Fazer previsões no conjunto de teste\n",
    "y_pred = rf.predict(X_test)\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "class_report = classification_report(y_test, y_pred)\n",
    "\n",
    "print(f\"Acurácia: {accuracy:.4f}\\n\")\n",
    "print(f\"Relatório de Classificação:\\n{class_report}\\n\")\n",
    "print(f\"Matriz de Confusão:\\n{conf_matrix}\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Finetuning de Hiperparâmetros\n",
    "\n",
    "Após o treinamento inicial do modelo, decidimos realizar um ajuste de hiperparâmetros para otimizar ainda mais seu desempenho. O ajuste de hiperparâmetros é uma etapa crucial no desenvolvimento de modelos de machine learning, pois permite encontrar a combinação ideal de parâmetros que maximiza a acurácia e melhora a generalização do modelo para novos dados.\n",
    "\n",
    "Nesta fase, utilizamos a classe RandomizedSearchCV do Scikit-Learn, que nos permite explorar uma combinação de parâmetros de forma aleatória, economizando tempo em comparação com uma busca exaustiva. Especificamente, definimos um dicionário param_dist com os seguintes hiperparâmetros a serem ajustados:\n",
    "\n",
    "- n_estimators: número de árvores na floresta (50 ou 100).\n",
    "- max_depth: profundidade máxima das árvores (10 ou 30).\n",
    "- min_samples_split: número mínimo de amostras necessárias para dividir um nó (2 ou 5).\n",
    "- min_samples_leaf: número mínimo de amostras em um nó folha (1 ou 2).\n",
    "- bootstrap: se as amostras devem ser extraídas com reposição (True ou False).\n",
    "\n",
    "Com isso, criamos uma instância do RandomForestClassifier e aplicamos o RandomizedSearchCV, configurando 10 iterações e uma validação cruzada de 3 dobras. O modelo ajustado foi então avaliado no conjunto de teste.\n",
    "\n",
    "A acurácia obtida após o ajuste foi avaliada e impressa, juntamente com um relatório de classificação e a matriz de confusão, que fornecem uma visão abrangente do desempenho do modelo após a otimização.\n",
    "\n",
    "Por fim, exibimos os melhores hiperparâmetros encontrados durante o ajuste, que podem ser utilizados para futuros treinamentos ou como referência para ajustar outros modelos. Essa abordagem não apenas melhora a performance do modelo, mas também fornece insights valiosos sobre como os diferentes parâmetros afetam a previsão da popularidade das músicas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parâmetros a serem ajustados\n",
    "param_dist = {\n",
    "    'n_estimators': [50, 100],          \n",
    "    'max_depth': [10, 30],           \n",
    "    'min_samples_split': [2, 5],              \n",
    "    'min_samples_leaf': [1, 2],                 \n",
    "    'bootstrap': [True, False]                     \n",
    "}\n",
    "\n",
    "# Criar o modelo RandomForestClassifier\n",
    "rf = RandomForestClassifier(random_state=42)\n",
    "\n",
    "# RandomizedSearchCV\n",
    "rf_random = RandomizedSearchCV(estimator=rf, param_distributions=param_dist, n_iter=10, \n",
    "                               cv=3, verbose=2, random_state=42, n_jobs=-1)\n",
    "\n",
    "# Ajustar o modelo\n",
    "rf_random.fit(X_train, y_train)\n",
    "\n",
    "# Fazer previsões no conjunto de teste\n",
    "y_pred = rf_random.predict(X_test)\n",
    "\n",
    "# Avaliação\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "class_report = classification_report(y_test, y_pred)\n",
    "\n",
    "# Exibir os resultados\n",
    "print(f\"Acurácia: {accuracy:.4f}\\n\")\n",
    "print(f\"Relatório de Classificação:\\n{class_report}\\n\")\n",
    "print(f\"Matriz de Confusão:\\n{conf_matrix}\\n\")\n",
    "\n",
    "# Melhor modelo e hiperparâmetros\n",
    "print(f\"Melhores hiperparâmetros: {rf_random.best_params_}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Submissão dos resultados\n",
    "\n",
    "Após a otimização do modelo com o ajuste de hiperparâmetros, a próxima etapa consiste em fazer previsões sobre os dados de teste, que não incluíam a coluna de popularidade em nosso DataFrame. Para isso, o conjunto X_test foi definido como df_test, o qual contém as mesmas características acústicas e metadados das músicas a serem analisadas.\n",
    "\n",
    "O modelo ajustado, rf_random, foi então treinado novamente com os dados de treino X e y para garantir que estivesse completamente otimizado. Em seguida, utilizamos o método predict para gerar as previsões de popularidade para as músicas no conjunto de teste. As previsões foram armazenadas na variável test_pred.\n",
    "\n",
    "Para preparar os dados para a submissão, criamos um novo DataFrame chamado submissao, que contém duas colunas: track_unique_id, que identifica de forma única cada faixa, e popularity_target, que armazena as previsões de popularidade geradas pelo modelo, convertidas para o tipo inteiro.\n",
    "\n",
    "Por fim, para organizar os dados de forma adequada para a submissão no Kaggle, aplicamos uma operação de agrupamento, onde as entradas foram agrupadas pelo track_unique_id, garantindo que, em casos de duplicatas, apenas a previsão de popularidade mais alta fosse considerada. O resultado final foi então exportado para um arquivo CSV chamado submissao.csv, pronto para ser enviado como parte do projeto."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separa um novo conjunto de dados para comportar uma previsão de uma coluna não incluida no dataframe\n",
    "X_test = df_test\n",
    "\n",
    "rf_random.fit(X, y)\n",
    "test_pred = rf_random.predict(X_test)\n",
    "\n",
    "# Ajusta as colunas do novo dataframe para submissão da atividade\n",
    "submissao = pd.DataFrame({\n",
    "    'track_unique_id': df_test['track_unique_id'],\n",
    "    'popularity_target': test_pred.astype(int)\n",
    "})\n",
    "\n",
    "# Organiza e agrupa as colunas para a exporação em CSV\n",
    "submissao_agrupada = submissao.groupby('track_unique_id', as_index=False).agg({'popularity_target': 'max'})\n",
    "submissao_agrupada.to_csv('submissao.csv', index=False)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
